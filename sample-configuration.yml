data-pulse:
  execution: 
    type: on-demand # Another option could be interval - more options would be available regarding this option
    strategy: batch # Another option could be stream
    data-sample:
      limitations:
        time-range: #mandatory
            format: hh:mm:ss.SSS-dd/MM/yyyy
            segmentation: none/minutes/hours/days/monthes  #options: minutes, hours, days, months, none
            gte: 13:00:00.000-15/01/2026
            lte: 15:00:00.000-15/01/2026
        rows-count: #optional
          order-by-field: INSERTION_TIME 
          value: 50
          relation: LAST #FIRST/LAST
        size: #optional - further discussion is required on this since this option will filter after the query execution - what do we do in that case?
          value: 1500MB 
  datasources:
    raw: #some name - would be helpful for linking which validations for each source if it gets complicated we could deploy additional instance
      type: oracle
      jdbc-url: jdbc:oracle:thin:@//localhost:1521/XEPDB1
      username: user
      password: password
      table: "RAW"
      where-clause: | #Optional - can be used to filter our data sample even more
        FIELD1 = 'VALUE1' AND IS_ON_SALE = TRUE AND......

    yellow_taxi_2019_01:
      type: oracle
      jdbc-url: jdbc:oracle:thin:@//localhost:1521/XEPDB1
      username: user
      password: password
      table: yellow_taxi_rides

  dq-tests: 
    - name: "Missing Pickup Time"
      description: "Checks the rides count with missing pickup time"
      datasource: yellow_taxi_2019_01
      type: sql
      sink: yellow_taxi_sink
      query: | #{data-sample} means a predefined keyword that we will require the users in order to inject the data-sample query
        SELECT
          SUM(CASE WHEN pickup_datetime IS NULL THEN 1 ELSE 0 END) AS null_pickup_dt,
        FROM {data-sample};
      thresholds: #Optional - only if we want to label the execution result so the sink will also include a boolean field for each metric
        metric-field: null_pickup_dt
        sanity-threshold: 
          value: 30
          relation: LTE #Another option could be LT/GT/GTE
        acceptable-threshold:   
          value: 50
          relation: LTE
        
    - name: "Payment type segmentation"
      description: "Chekcs the payment type segmentation"
      datasource: yellow_taxi_2019_01
      type: sql
      sink: yellow_taxi_sink
      query: |
        SELECT
          payment_type,
          COUNT(*) AS rides_count
        FROM {data-sample}
        GROUP BY payment_type;
      thresholds:
        metric-field: rides_count
        sanity-threshold: 
          value: 30
          relation: LTE
        acceptable-threshold:   
          value: 50
          relation: LTE

    - name: "Ride duration percentiles"
      description: "Checks the rides duration percentiles"
      datasource: yellow_taxi_2019_01
      type: sql
      sink: yellow_taxi_sink
      query: |
        SELECT
          PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY ride_duration_min) AS p50_minutes,
          PERCENTILE_CONT(0.90) WITHIN GROUP (ORDER BY ride_duration_min) AS p90_minutes,
        FROM (
          SELECT
            (tpep_dropoff_datetime - tpep_pickup_datetime) * 24 * 60 AS ride_duration_min
          FROM {data-sample}
        )

  output-sinks:
    yellow_taxi_sink:
      type: elasticsearch
      host: http://localhost:9200
      index: dq-output-index

    raw-metrics:
      type: elasticsearch
      host: http://localhost:9200
      index: dq-output-index

    processed-metrics:
      type: filesystem
      target-path: /some/path
